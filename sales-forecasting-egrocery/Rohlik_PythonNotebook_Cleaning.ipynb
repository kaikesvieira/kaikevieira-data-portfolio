{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8sjm8lBaLOem"
   },
   "source": [
    "# **1. Overview**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6mnioeyRLOeo"
   },
   "source": [
    "## Description\n",
    "\n",
    "**Why This Matters**\n",
    "\n",
    "Accurate sales forecasts are crucial for planning process, supply chain processes, delivery logistics and inventory management. By optimizing forecasts, we can minimize waste and streamline operations, making our e-grocery services more sustainable and efficient.\n",
    "\n",
    "**Your Impact**\n",
    "\n",
    "Your participation in this challenge will directly contribute to Rohlik mission of sustainable and efficient e-grocery delivery. Your insights will help us enhance customer service and achieve a greener future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tvhPlaLJLOep"
   },
   "source": [
    "We are relaunching the Challenge with prizes.\n",
    "\n",
    "Rohlik Group, a leading European e-grocery innovator, is revolutionising the food retail industry. We operate across 11 warehouses in Czech Republic, Germany, Austria, Hungary, and Romania.\n",
    "\n",
    "We are now transitioning from the Rohlik Orders Forecasting Challenge to the Rohlik Sales Forecasting Challenge, as we continue with our set of challenges. This challenge focuses on predicting the sales of each selected warehouse inventory for next 14 days using historical sales data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cmwjnKCWLOer"
   },
   "source": [
    "## Evaluation\n",
    "\n",
    "Submissions are evaluated on Weighted Mean Absolute Error (WMAE) between the predicted sales and the actual sales. Weights for the test evaluation can be found in the Data section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wn10LuHRLOer"
   },
   "source": [
    "## Submission File\n",
    "\n",
    "For each ID in the test set, you must predict a probability for the TARGET variable. The file should contain a header and have the following format:\n",
    "\n",
    "id,sales_hat\n",
    "\n",
    "840_2024-06-10,12.01\n",
    "\n",
    "2317_2024-06-15,13.32\n",
    "\n",
    "738_2024-06-10,14.12\n",
    "\n",
    "3894_2024-06-11,3.03\n",
    "\n",
    "3393_2024-06-08,53.03\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SzQAZ8W-LOer"
   },
   "source": [
    "## Prizes\n",
    "Leaderboard prizes\n",
    "\n",
    "1st place - $4,000\n",
    "\n",
    "2nd place - $4,000\n",
    "\n",
    "3rd place - $2,000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4IywSr2PLOes"
   },
   "source": [
    "## Citation\n",
    "\n",
    "MichalKecera. Rohlik Sales Forecasting Challenge. https://kaggle.com/competitions/rohlik-sales-forecasting-challenge-v2, 2024. Kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0opgBH9ILOes"
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xeIeoID4LOes"
   },
   "source": [
    "## Dataset Description\n",
    "You are provided with historical sales data for selected Rohlik inventory and date. IDs, sales, total orders and price columns are altered to keep the real values confidential. Some features are not available in test as they are not known at the moment of making the prediction. The task is to forecast the sales column for a given id, constructed from unique_id and date (e. g. id 1226_2024-06-03 from unique_id 1226 and date 2024-06-03), for the test set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FtH0nBRILOes"
   },
   "source": [
    "## Files\n",
    "- **sales_train.csv** - training set containing the historical sales data for given date and inventory with selected features described below\n",
    "- **sales_test.csv** - full testing set\n",
    "- **inventory.csv** - additional information about inventory like its product (same products across all warehouses share same product unique id and name, but have different unique id)\n",
    "- **solution.csv** - full submission file in the correct format\n",
    "- **calendar.csv** - calendar containing data about holidays or warehouse specific events, some columns are already in the train data but there are additional rows in this file for dates where some warehouses could be closed due to public holiday or Sunday (and therefore they are not in the train set)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W0zt0zXcLOet"
   },
   "source": [
    "## Columns\n",
    "**sales_train.csv** and **sales_test.csv**\n",
    "\n",
    "- `unique_id` - unique id for inventory\n",
    "- `date` - date\n",
    "- `warehouse` - warehouse name\n",
    "- `total_orders` - historical orders for selected Rohlik warehouse known also for test set as a part of this challenge\n",
    "- `sales` - Target value, sales volume (either in pcs or kg) adjusted by availability. The sales with lower availability than 1 are already adjusted to full potential sales by Rohlik internal logic. There might be missing dates both in train and test for a given inventory due to various reasons. This column is missing in test.csv as it is target variable.\n",
    "- `sell_price_main` - sell price\n",
    "- `availability` - proportion of the day that the inventory was available to customers. The inventory doesn't need to be available at all times. A value of 1 means it was available for the entire day. This column is missing in test.csv as it is not known at the moment of making the prediction.\n",
    "- `type_0_discount`, type_1_discount, … - Rohlik is running different types of promo sale actions, these show the percentage of the original price during promo ((original price - current_price) / original_price). Multiple discounts with different type can be run at the same time, but always the highest possible discount among these types is used for sales. Negative discount value should be interpreted as no discount.\n",
    "\n",
    "**inventory.csv**\n",
    "\n",
    "- `unique_id` - inventory id for a single keeping unit\n",
    "- `product_unique_id` - product id, inventory in each warehouse has the same product unique id (same products across all warehouses has the same product id, but different unique id)\n",
    "- `name` - inventory id for a single keeping unit\n",
    "L1_category_name, L2_category_name, … - name of the internal category, the higher the number, the more granular information is present\n",
    "- `warehouse` - warehouse name\n",
    "\n",
    "**calendar.csv**\n",
    "\n",
    "- `warehouse` - warehouse name\n",
    "- `date` - date\n",
    "- `holiday_name` - name of public holiday if any\n",
    "- `holiday` - 0/1 indicating the presence of holidays\n",
    "- `shops_closed` - public holiday with most of the shops or large part of shops closed\n",
    "- `winter_school_holidays` - winter school holidays\n",
    "- `school_holidays` - school holidays\n",
    "\n",
    "**test_weights.csv**\n",
    "\n",
    "- `unique_id` - inventory id for a single keeping unit\n",
    "- `weight` - weight used for final metric computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# **Import and merge DFs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define the correct path using forward slashes\n",
    "path = r\"C:\\\\Users\\defaultuser0\\\\OneDrive\\Documents\\\\GitHub\\\\CapstoneProject-RohlikSalesForecasting\\\\rohlik-sales-forecasting-challenge-v2\\Data\"\n",
    "\n",
    "# Load datasets\n",
    "sales_train = pd.read_csv(fr\"{path}\\sales_train.csv\", index_col=False)\n",
    "sales_test = pd.read_csv(fr\"{path}\\sales_test.csv\", index_col=False)\n",
    "weights = pd.read_csv(fr\"{path}\\test_weights.csv\", index_col=False)\n",
    "solution = pd.read_csv(fr\"{path}\\solution.csv\", index_col=False)\n",
    "inventory = pd.read_csv(fr\"{path}\\inventory.csv\", index_col=False)\n",
    "calendar = pd.read_csv(fr\"{path}\\calendar.csv\", index_col=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4007419, 14)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop preidentified 52 rows with NA values\n",
    "sales_train.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(198931, 14)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_train[sales_train['warehouse'] == 'Frankfurt_1'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat sales dataframes\n",
    "df = pd.concat([sales_train,\n",
    "                sales_test],\n",
    "                ignore_index=True)\n",
    "# Ensure the 'date' column is in datetime format\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "calendar['date'] = pd.to_datetime(calendar['date'])\n",
    "\n",
    "df = df.merge(calendar, on=['date', 'warehouse'], how='left')\n",
    "df = df.merge(inventory, on=['unique_id', 'warehouse'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unique_id                       0\n",
       "date                            0\n",
       "warehouse                       0\n",
       "total_orders                    0\n",
       "sales                       47021\n",
       "sell_price_main                 0\n",
       "availability                47021\n",
       "type_0_discount                 0\n",
       "type_1_discount                 0\n",
       "type_2_discount                 0\n",
       "type_3_discount                 0\n",
       "type_4_discount                 0\n",
       "type_5_discount                 0\n",
       "type_6_discount                 0\n",
       "holiday_name              3890621\n",
       "holiday                         0\n",
       "shops_closed                    0\n",
       "winter_school_holidays          0\n",
       "school_holidays                 0\n",
       "product_unique_id               0\n",
       "name                            0\n",
       "L1_category_name_en             0\n",
       "L2_category_name_en             0\n",
       "L3_category_name_en             0\n",
       "L4_category_name_en             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump cleaned df\n",
    "\n",
    "df.to_csv(fr\"{path}\\dataframes\\df_cleaned.csv\", index_label=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [
    "8sjm8lBaLOem",
    "0opgBH9ILOes",
    "3ORWG1r9kZm8",
    "ycQUvkHFkZm8",
    "FrqQV47tkZm8",
    "aY8xEIQjkZm9",
    "3qzAVpPhkZm-",
    "z1lUgXfokZnD"
   ],
   "gpuType": "V28",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
